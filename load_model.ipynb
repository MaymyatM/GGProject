{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOHio1QPp4GhI0XmqYgc+W2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tayyMem/ProjectGG/blob/main/load_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
        "import torch\n",
        "\n",
       # "repo_name = \"TayyMem/Grammar_Spelling_Correction\"\n",
        "\n",
"repo_name = "TayyMem/ProjectGG_Testing3"
"# Load model and tokenizer from Hugging Face\n",
        "tokenizer = T5Tokenizer.from_pretrained(repo_name)\n",
        "model = T5ForConditionalGeneration.from_pretrained(repo_name)\n",
        "\n",
        "print(\"Model loaded successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uMfgM1GCLCk",
        "outputId": "4b8a661b-c311-4a10-fa30-5ed6640f3993"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://huggingface.co/docs/transformers/v4.15.0/en/model_sharing#add-a-model-card"
      ],
      "metadata": {
        "id": "DcYq3OLhK1aC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "# Define the device\n",
        "# If a GPU is available, it will use the GPU. Otherwise, it will use the CPU.\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "example_sentence = [\n",
        "    \"He is there when I had finished having dinner\",\n",
        "    \"She go to school everyday.\",\n",
        "    \"The clothes he wear is given by me.\",\n",
        "    \"he mistaked that it were me.\",\n",
        "    \"I comitted to this job and i planned it perfect\",\n",
        "    \"This are the luxerious clothes I have ever want.\",\n",
        "]\n",
        "\n",
        "#tokenizing the example sentence\n",
        "testing_input = tokenizer(\n",
        "    example_sentence,\n",
        "    max_length=256,\n",
        "    truncation=True,\n",
        "    padding=True,\n",
        "    return_tensors='pt').to(device)\n",
        "\n",
        "#need to read why this one below.\n",
        "testing_output = model.generate(\n",
        "    input_ids= testing_input[\"input_ids\"],\n",
        "    attention_mask= testing_input[\"attention_mask\"],\n",
        "    max_length=256) # A way to predict data\n",
        "\n",
        "corrected_sentences = [tokenizer.decode(output, skip_special_tokens=True) for output in testing_output]\n",
        "\n",
        "for i in range(len(example_sentence)):\n",
        "    print(f\"❌ Incorrect: {example_sentence[i]}\")\n",
        "    print(f\"✅ Corrected: {corrected_sentences[i]}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70_cXp2JMhJv",
        "outputId": "96af93d8-98c5-41cc-a070-a52d9af0afc2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ Incorrect: He is there when I had finished having dinner\n",
            "✅ Corrected: He is there when i finished having dinner\n",
            "\n",
            "❌ Incorrect: She go to school everyday.\n",
            "✅ Corrected: She goes to school everyday.\n",
            "\n",
            "❌ Incorrect: The clothes he wear is given by me.\n",
            "✅ Corrected: The clothes he wear are given by me.\n",
            "\n",
            "❌ Incorrect: he mistaked that it were me.\n",
            "✅ Corrected: He mistakenly said that it was me.\n",
            "\n",
            "❌ Incorrect: I comitted to this job and i planned it perfect\n",
            "✅ Corrected: I have been working on this job and i planned it perfectly\n",
            "\n",
            "❌ Incorrect: This are the luxerious clothes I have ever want.\n",
            "✅ Corrected: These are the luxerious clothes i have ever wanted.\n",
            "\n",
            "❌ Incorrect: this was there wen i  gets here. but he say i does it.\n",
            "✅ Corrected: I was there wen i got here. but he said i did it.\n",
            "\n",
            "❌ Incorrect: i dont like this wather.\n",
            "✅ Corrected: I dont like this.\n",
            "\n",
            "❌ Incorrect: wather is cold\n",
            "✅ Corrected: It is colder\n",
            "\n"
          ]
        }
      ]
    }
  ]
}
